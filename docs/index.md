---
layout: home
title: 关于OpenMind
---

## 关于OpenMind

收集分享各种深度学习相关内容

## 关于资源

内容中难免会大量使用Youtube、Google、Facebook、Github访问困难的资源，如何访问需用户自行解决。

## License

This work is open sourced under the Apache License, Version 2.0.


# 算法& 模型

各种算法合集，各种模型合集

潜在语义分析（latent semantic analysis）
主题生成模型（Latent Dirichlet Allocation）
因子分析（Factor Analysis）
核函主成分（kernal pca）
主成分方法（PCA）
层次聚类（Hierarchical clustering）——支持多种距离
Kmeans算法
Knn算法
典型相关分析（CCA）
逻辑回归（Logistic regression）
稳健回归（Robustness regression）
多项式回归（Polynomial regression——多项式基函数回归）
高斯过程回归（Gaussian Process Regression）
偏最小二乘回归（PLS）
套索回归（Lasso）
弹性网络回归（Elastic Net）
贝叶斯回归（Bayesian Regression）
AdaBoost
GBDT（Gradient Tree Boosting）
最小二乘回归（OLS）
岭回归（Ridge Regression）
核岭回归（Kernel ridge regression）
支持向量机回归（SVR）
决策树算法（decision tree）
Bagging
随机森林（Random Forest）
朴素贝叶斯算法（Naive Bayes）
二次判别分析（QDA）
支持向量机（SVM）
Knn算法
线性判别分析（LDA）
big bird
Switch Transformer
MT5
UniLM
alphafold2
XLM
XLM-ProphetNet
MASS
PREFOMER
XLM-RoBERTa
XLNet
XLSR-Wav2Vec2
Reformer
RetriBERT
RoBERTa
Speech2Text
SqueezeBERT
T5
TAPAS
Transformer XL
Wav2Vec2
MPNet
OpenAI GPT
OpenAI GPT2
Pegasus
PhoBERT
ProphetNet
RAG
M2M100
MarianMT
MBart and MBart-50
MobileBERT
LXMERT
Longformer
LED
LayoutLM
I-BERT
herBERT
Funnel Transformer
FSMT
FlauBERT
Encoder Decoder Models
ELECTRA
DPR
DistilBERT
DialoGPT
DeBERTa
CTRL
ConvBERT
CamemBERT
BORT
BertGeneration
Blenderbot
Bertweet
BARThez
BART
ALBERT
NNLM(Neural Network Language Model) 
BERT
The Transformer
Bi-LSTM with Attention 
Seq2Seq
Seq2Seq with Attention
Bi-LSTM
TextLSTM 
TextCNN
TextRNN
FastText(Application Level)
Word2Vec(Skip-gram)











# 数据

开源数据

# 学习资料

好用的学习资料
